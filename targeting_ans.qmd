---
title: "Customer Targeting Analysis"
execute: 
  echo: true
  eval: true
format:
  html:
    code-fold: false
    self-contained: true
jupyter: python3
---


## Loading Libraries

```{python}
# Import necessary libraries
import polars as pl
import numpy as np
import pandas as pd
import plotly.express as px
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.cluster import KMeans
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, accuracy_score,classification_report
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression


#uncomment the following two lines if you want to ignore warnings
#import warnings
#warnings.filterwarnings('ignore') 

# Set random seed for reproducibility
np.random.seed(10)

```


## Introduction

This document demonstrates customer targeting using results from segmentation using K-means clustering and classification using XGboost, a high-performance machine learning method. We employ the `Polars` library for data manipulation and `Plotly Express` for visualization.




## Customer Data Loading and Preparation

Let's go back to our customer dataset. We will load in the data, segment the customers, then train classification methods so that we can predict customer segment assignments for prospective/future customers.


### Email Data

```{python}
# Load email dataset
email = pl.read_csv("https://raw.githubusercontent.com/numktg/data/main/email.csv")

# Select relevant columns for clustering
email_bases = email.select([
    "avg_distance",
    "n_purchase",
    "discount_purchase",
    "n_reward",
    "avg_npassengers",
    "avg_price"
])
```

## K-means Clustering

- create k-means pipeline
```{python}
def create_pipeline(num_clusters, random_seed = 42):
    """
    Creates a machine learning pipeline with a scaler and KMeans.
    """
    pipeline = Pipeline([
        ('scaler', StandardScaler()),
        ('kmeans', KMeans(n_clusters=num_clusters, random_state=random_seed))
    ])
    return pipeline



```

- Run k-means with k = 3
```{python}

optimal_k = 3

# Run K-means clustering

email_kmeans_pipeline = create_pipeline(optimal_k)
email_kmeans_pipeline.fit(email_bases)


# Add cluster assignments to the original data
email_with_clusters = email.with_columns(
    pl.Series(
        "segment_number",
        email_kmeans_pipeline['kmeans'].labels_ + 1
        ).cast(pl.Utf8).cast(pl.Categorical)  # Make cluster labels 1-indexed
)

email_with_clusters.head()


```

## Merging with Demographic Data

### Load Demographics

```{python}
# Load demographic data
demo = pl.read_csv("https://raw.githubusercontent.com/numktg/data/main/email_demo.csv")

# Combine email and demo data using a left join
email_joined = email_with_clusters.join(demo, on='ID', how='left')

# Convert to Pandas DataFrame for easier handling with sklearn
email_df = email_joined.to_pandas()

# Encode the target variable using LabelEncoder
label_encoder = LabelEncoder()

email_df['segment_number'] = label_encoder.fit_transform(email_joined['segment_number'])

# Define features and target
features = ['age', 'Education', 'Income', 'Marital_Status', 'Occupation', 'Children', 'Region', 'Gender']
target = 'segment_number'
```

## Data Splitting

```{python}
# Split data into training and test sets
train, test = train_test_split(email_df, test_size=0.3, random_state=101)
```


## Classification using Machine Learning Models

### Additional pre-processing

```{python}


# Define column transformer for one-hot encoding categorical features
categorical_features = ['Education', 'Marital_Status', 'Occupation', 'Region', 'Gender', 'Income']
numeric_features = ['age', 'Children']

preprocessor = ColumnTransformer(
    transformers=[
        ('num', 'passthrough', numeric_features),
        ('cat', OneHotEncoder(), categorical_features)
    ]
)
```



### Train and Evaluate One Model

- First, specify the model and build pipeline
- Then, fit the model to the training data
```{python}
logit_model = LogisticRegression(max_iter=1000, solver='liblinear')

pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', logit_model)
])
    
# Fit the pipeline on training data
pipeline.fit(train[features], train[target])
```



- Now, ready to predict on test set

```{python}


test['pred_seg'] = pipeline.predict(test[features])

# Ensure target names are str (per classification_report requirement)
target_names = [str(name) for name in label_encoder.classes_]

# Create confusion matrix and compute accuracy
conf_matrix = confusion_matrix(test[target], test['pred_seg'])
accuracy = accuracy_score(test[target], test['pred_seg'])

# Print results
print(f"\nModel: Logistic regression")
print("Confusion Matrix:\n", conf_matrix)
print("Accuracy:", accuracy)

```



## Use Trained Model to Predict Future Customers

- First, load in the "prospect" data set, which contains prospective customers.

```{python}
# Load the prospective customer data
prospect_pl = pl.read_csv("https://raw.githubusercontent.com/numktg/data/main/email_prospect.csv")

# Convert prospect data to Pandas DataFrame

prospect_df = prospect_pl.to_pandas()

# Use the same preprocessing pipeline
# Only select features that match the training data
prospect_features = prospect_df[features]
```


- Now, use the trained model to make prediction

```{python}

# Make predictions on the unseen data
predicted = pipeline.predict(prospect_features)

prospect_pl = prospect_pl.with_columns(
    pl.Series(predicted).alias('predicted_segment')
)


# Display some of the predictions
print(prospect_pl['predicted_segment'].head(15))
```

## Analyzing Profitability

### Profitability by Segment

```{python}
# Analyze which segment is most profitable
profitability = (
    email_with_clusters
    .group_by('segment_number')
    .agg([
        pl.col('total_revenue').mean().alias('avg_revenue'),
        pl.len().alias('num_customers')
        ])
    .with_columns(pl.col('segment_number').cast(pl.Int64))
    .sort('segment_number')
)

profitability
```



### Revenue Estimation

```{python}
# Estimate potential revenue from prospects
revenue_estimate = (
    prospect_pl
    .join(profitability,
          left_on='predicted_segment',
          right_on='segment_number',
          how='left')
    .select(pl.col('avg_revenue'))
    .sum()
)

print(revenue_estimate)

# Print the revenue estimate in a readable format
# Note that we convert dataframe to a number by extracting the cell [0,0] since this dataframe has only 1 element in it
print(f"Estimated Revenue: {revenue_estimate[0,0]:.2f}")
```

## Conclusion

In this analysis, we demonstrated customer segmentation using K-means. We then built a logistic regression model to predict customer's segment assignment. With that, we were able to the trained model to predict future customers' segment assignments. The segment with the highest average revenue should be targeted for future marketing strategies. The potential revenue from converting all prospects was also estimated. This approach helps in identifying the most valuable customer segments and optimizing marketing efforts.


### Key Points in the Document


1. **Data Loading and Preparation**: Loads the datasets using Polars and selects relevant columns for analysis.

2. **K-means Clustering**: Performs K-means clustering on the email data to segment customers into three groups.

3. **Merging with Demographic Data**: Joins the clustered email data with demographic information.

4. **Data Splitting**: Splits the combined dataset into training and test sets.

5. **Model Training**: Trains a logistic regression model to classify customers based on demographics and evaluates them with a confusion matrix.

6. **Predicting Future Customers**: Applies the trained logistic regression model to predict the segment of new prospective customers.

7. **Analyzing Profitability**: Identifies the most profitable customer segment and estimates potential revenue from prospects.


